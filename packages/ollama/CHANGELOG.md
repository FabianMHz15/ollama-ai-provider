# ollama-ai-provider

## 0.15.0

### Minor Changes

- Add missed Ollama API settings

## 0.14.0

### Minor Changes

- Upgrade ai sdk and middleware examples

## 0.13.0

### Minor Changes

- Add custom provider support

## 0.12.1

### Patch Changes

- Minor updates

## 0.12.0

### Minor Changes

- Update to Vercel AI SDK 3.3
- Added support to sending custom headers
- Added support to stopSequences and topK settings
- Added settings to disable experimental stream tooling

## 0.11.0

### Minor Changes

- add native ollama tool support

## 0.10.0

- fix stream split lines

## 0.9.1

### Patch Changes

- Fix console assistant extra messages

## 0.9.0

### Minor Changes

- New sdk-ai features:

  - Intercepting fetch requests
  - Provider Management

- New examples:

- Intercepting fetch requests
- Provider Management
- on-finish event
- update complex examples

## 0.8.0

### Minor Changes

- Update ai-sdk dependencies
- Migrate createJsonStreamResponseHandler to ai-sdk utils

## 0.7.0

### Minor Changes

- Add experimental tool streaming

## 0.6.0

### Minor Changes

- Add embedding model

## 0.5.1

### Patch Changes

- Minor updates

## 0.5.0

### Minor Changes

- Add tool usage

## 0.4.0

### Minor Changes

- - Added more models autocompletion
  - Added extra ollama settings

## 0.3.0

### Minor Changes

- Add support to images with llava

## 0.2.0

### Minor Changes

- Add object generation support

## 0.1.0

### Patch Changes

- First public release
